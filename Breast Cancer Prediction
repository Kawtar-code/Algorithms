#This algorithm diagnoses breast cancer, based off of data.

#import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#Load the data
from google.colab import files
uploaded = files.upload()
df = pd.read_csv("breastcancerdata.csv")
df.head(10)

#Count the number of rows and columns in the dataset
df.shape

#Count the number of empty values in each column
df.isna().sum()

#Get a count of the Malignant (M) or Benign (B) cells
df["diagnosis"].value_counts()

#Visualize count
sns.countplot(df["diagnosis"], label="count")

#Look at the data types to see which columns need to be encoded
df.dtypes

#encode the categorical data values
from sklearn.preprocessing import LabelEncoder
labelencoder_Y = LabelEncoder()
df.iloc[:,1] = labelencoder_Y.fit_transform(df.iloc[:,1].values)

#Create a pairplot
sns.pairplot(df.iloc[:,1:5], hue ="diagnosis")

#print the first 5 rows of the new data
df.head(5)

#get the correlation of the columns
df.iloc[:,1:12].corr()

#visualize the correlation
plt.figure(figsize=(10,10))
sns.heatmap(df.iloc[:,1:12].corr(),annot=True, fmt='.0%')

X = df.iloc[:,2:31].values
Y = df.iloc[:,1].values
type (X)

#split the data, 75% training, 25% testing
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25 , random_state = 0)

#Scale the data (feature scaling)
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.fit_transform(X_test)

from sklearn.ensemble import RandomForestClassifier

# Create a function for the models
 def models(X_train, Y_train):

  #Logistic Regression
  from sklearn.linear_model import LogisticRegression
  log = LogisticRegression(random_state=0)
  log.fit(X_train, Y_train)

  #Decision tree
  from sklearn.tree import DecisionTreeClassifier
  tree = DecisionTreeClassifier(criterion = 'entropy', random_state=0)
  tree.fit(X_train, Y_train)

  #Random Forest Classifier
  from sklearn.ensemble import RandomForestClassifier
  forest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
  forest.fit(X_train, Y_train)

  #Print the models accuracy on the training data
  print('[0]Logistic Regression Training Accuracy:', log.score(X_train, Y_train))
  print('[1]Decision Tree Classifier Training Accuracy:', tree.score(X_train, Y_train))
  print('[2]Random Forest Classifier Training Accuracy:', forest.score(X_train, Y_train))
  return log, tree, forest

# Getting all of the models
model = models(X_train, Y_train)

#test model accuracy on test data on confusion matrix
from sklearn.metrics import confusion_matrix
for i in range( len(model) ):
   print('Model ', i)
   cm = confusion_matrix(Y_test, model[i].predict(X_test))
   TP = cm[0][0]
   TN = cm[1][1]
   FN = cm[1][0]
   FP = cm[0][1]
print(cm)
print('Testing Accuracy = ', (TP + TN)/(TP + TN + FN + FP))
print()

#show another way to get metrics of the models
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
for i in range( len(model) ):
   print('Model ', i)
   print( classification_report(Y_test, model [i]. predict(X_test)))
   print (accuracy_score (Y_test, model [i]. predict(X_test)))
   print()

#Print the predicition of Random Forest Classifier Model
pred = model[2].predict(X_test)
print(pred)
print()
print(Y_test)
